{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import skimage as sk\n",
    "import skimage.io as skio\n",
    "import imageio\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.spatial import Delaunay\n",
    "from scipy.interpolate import griddata\n",
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im1 = sk.img_as_float(plt.imread('photos/thomas.jpg')/255)\n",
    "im2 = sk.img_as_float(plt.imread('photos/kanye.jpg')/255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Triangulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_num is either 1 or 2\n",
    "def triangulate(image_num, outfile):\n",
    "    curr_im = eval(f'im{image_num}')\n",
    "\n",
    "    # FOR .JSON FILES\n",
    "    # Compute triangulation for image via Delaunay function\n",
    "    with open('points/thomas_kanye.json') as f:\n",
    "        correspondences = json.load(f)\n",
    "        points = np.array(correspondences[f'im{image_num}Points'])\n",
    "        tri = Delaunay(points)\n",
    "\n",
    "    # Save image\n",
    "    # plt.imshow(curr_im)\n",
    "    # plt.triplot(points[:,0], points[:,1], tri.simplices)\n",
    "    # plt.plot(points[:,0], points[:,1], 'o', markersize=2)\n",
    "    # plt.axis('off')\n",
    "    # plt.tight_layout(pad=0)\n",
    "    # plt.savefig(outfile, bbox_inches='tight', pad_inches=0)\n",
    "    # plt.close()\n",
    "    # plt.show()\n",
    "\n",
    "    return points, tri\n",
    "\n",
    "im1_points, tri = triangulate(1, 'part1_results/triangulated_thomas.jpg')\n",
    "im2_points, _ = triangulate(2, 'part1_results/triangulated_kanye.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Computing the \"mid-way\" face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_points = 0.5 * (im1_points + im2_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeAffine(tri1_points, tri2_points):\n",
    "    # Add ones to create homogeneous coordinates for the points\n",
    "    A = np.vstack((tri1_points.T, np.ones((1, 3))))\n",
    "    B = np.vstack((tri2_points.T, np.ones((1, 3))))\n",
    "    return np.linalg.solve(A.T, B.T).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warp function to warp one image to the midway shape\n",
    "def warp(im, im_points, average_points, tri):\n",
    "    num_triangles = len(tri.simplices)\n",
    "    warped_im = np.zeros_like(im)\n",
    "\n",
    "    # Loop over each triangle\n",
    "    for t in range(num_triangles):\n",
    "        # Get the current triangle from both source and target\n",
    "        curr_triangle = tri.simplices[t]\n",
    "        curr_avg_triangle = tri.simplices[t]\n",
    "\n",
    "        # Compute the affine transformation from source to average shape\n",
    "        T = computeAffine(im_points[curr_triangle], average_points[curr_avg_triangle])\n",
    "\n",
    "        # Create mask for the target triangle\n",
    "        avg_triangle_points = average_points[curr_avg_triangle]\n",
    "        rr, cc = sk.draw.polygon(avg_triangle_points[:, 1], avg_triangle_points[:, 0], im.shape)\n",
    "\n",
    "        # Create a set of points inside the triangle\n",
    "        target_points = np.vstack((cc, rr)).T\n",
    "        target_points_homog = np.hstack((target_points, np.ones((len(target_points), 1))))\n",
    "\n",
    "        # Apply the inverse transformation to map target points to source image\n",
    "        T_inv = np.linalg.inv(T)\n",
    "        source_points = (T_inv @ target_points_homog.T).T[:, :2]\n",
    "\n",
    "        # Interpolate pixel values from the source image for each color channel\n",
    "        row_coords, col_coords = source_points[:, 1], source_points[:, 0]\n",
    "        coords = [row_coords, col_coords]\n",
    "        for c in range(im.shape[2]):\n",
    "            warped_im[rr, cc, c] = ndimage.map_coordinates(im[:, :, c], coords, order=1)\n",
    "\n",
    "    return warped_im"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: The morph sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def morph(im1, im2, im1_pts, im2_pts, tri, warp_frac, dissolve_frac):\n",
    "    average_points = warp_frac * im1_points + (1 - warp_frac) * im2_points\n",
    "    warped_im1 = warp(im1, im1_points, average_points, tri)\n",
    "    warped_im2 = warp(im2, im2_points, average_points, tri)\n",
    "    mid_way = dissolve_frac * warped_im1 + (1 - dissolve_frac) * warped_im2\n",
    "\n",
    "    # plt.imshow(mid_way)\n",
    "    # plt.axis('off')\n",
    "    # plt.tight_layout(pad=0)\n",
    "    # plt.show()\n",
    "\n",
    "    return mid_way\n",
    "\n",
    "morphed_im = morph(im1, im2, im1_points, im2_points, tri, 0.5, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate evolution and gif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []\n",
    "num_frames = 45\n",
    "\n",
    "for frame in range(num_frames):\n",
    "    threshold = frame / (num_frames - 1)\n",
    "    morphed_im = morph(im1, im2, im1_points, im2_points, tri, threshold, threshold)\n",
    "    frames.append(morphed_im)\n",
    "\n",
    "# Convert each frame to uint8\n",
    "frames = [np.clip(frame, 0, 1) * 255 for frame in frames]\n",
    "frames = [frame.astype(np.uint8) for frame in frames]\n",
    "\n",
    "imageio.mimsave('part3_results/morphed_kanye_thomas.gif', frames)\n",
    "\n",
    "# Create a 9x5 grid of plots\n",
    "fig, axes = plt.subplots(9, 5, figsize=(13, 27))\n",
    "fig.subplots_adjust(hspace=0.2, wspace=0.0)\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    if i < len(frames):\n",
    "        ax.imshow(frames[i])\n",
    "        ax.axis('off')\n",
    "        ax.set_title(f'Alpha: {i / (num_frames - 1):.2f}', fontsize=14)\n",
    "    else:\n",
    "        ax.axis('off')\n",
    "\n",
    "# fig.tight_layout(pad=1)\n",
    "# fig.savefig('part3_results/evolution_kanye_thomas.jpg')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4: The \"mean face\" of a population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pictures and images are from the [FEI Face database](https://fei.edu.br/~cet/facedatabase.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get file names of images\n",
    "target_directory = os.path.join(os.getcwd(), 'photos', 'smiling_men')\n",
    "contents = os.listdir(target_directory)\n",
    "filenames = [f for f in contents if os.path.isfile(os.path.join(target_directory, f))]\n",
    "filenames_without_ext = [os.path.splitext(f)[0] for f in filenames] # Remove the extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "\n",
    "for file in filenames:\n",
    "    im = sk.img_as_float(plt.imread(f'photos/smiling_men/{file}')/255)\n",
    "    images.append(im)\n",
    "\n",
    "height, width = images[0].shape[:2] # Get dimension of first image (all images have the same dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Triangulate all images\n",
    "im_points = []\n",
    "\n",
    "for points_file in filenames_without_ext:\n",
    "    points = np.loadtxt(f'points/smiling_men_points/{points_file}.pts', comments=(\"version:\", \"n_points:\", \"{\", \"}\"))\n",
    "    \n",
    "    # Define the corner points\n",
    "    corners = np.array([[0, 0], [width - 1, 0], [0, height - 1], [width - 1, height - 1]])\n",
    "    points = np.vstack((points, corners))\n",
    "    \n",
    "    tri = Delaunay(points)\n",
    "    im_points.append(points)\n",
    "\n",
    "men_average_points = (1 / len(im_points)) * sum(im_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warp all images\n",
    "warped_images = []\n",
    "\n",
    "count = 4\n",
    "\n",
    "for image, points in zip(images, im_points):\n",
    "    warped_im = warp(image, points, men_average_points, tri)\n",
    "    warped_images.append(warped_im)\n",
    "\n",
    "# Find average image\n",
    "average_smiling_man = (1 / len(warped_images)) * sum(warped_images)\n",
    "\n",
    "# Save image\n",
    "average_smiling_man = np.clip(average_smiling_man, 0, 1) * 255\n",
    "average_smiling_man = average_smiling_man.astype(np.uint8)\n",
    "\n",
    "# plt.imshow(average_smiling_man)\n",
    "# plt.axis('off')\n",
    "# plt.tight_layout(pad=0)\n",
    "# plt.savefig('part4_results/average_smiling_man.jpg', bbox_inches='tight', pad_inches=0)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 2x4 grid\n",
    "fig, axs = plt.subplots(2, 4, figsize=(10, 8))  # 2 rows and 4 columns\n",
    "axs = axs.flatten()  # Flatten the 2D array of axes\n",
    "\n",
    "# Iterate over the first four images and their corresponding warped images\n",
    "for i, (image, warped_im) in enumerate(zip(images[:4], warped_images[:4])):\n",
    "    # Display the original image in the first row\n",
    "    axs[i].imshow(image)\n",
    "    axs[i].axis('off')\n",
    "    axs[i].set_title('Original Face')\n",
    "\n",
    "    # Display the warped image in the second row\n",
    "    axs[i + 4].imshow(warped_im)  # Place warped images in the second row\n",
    "    axs[i + 4].axis('off')\n",
    "    axs[i + 4].set_title('Warped Face')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout(pad=0.5)\n",
    "plt.savefig('part4_results/face_vs_warped.jpg', bbox_inches='tight', pad_inches=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### My face (if I was average... and smiling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Crop and resize images\n",
    "\n",
    "cropped_thomas = im1[50:-110, 80:-90]\n",
    "# plt.imshow(cropped_thomas)\n",
    "# plt.axis('off')\n",
    "# plt.tight_layout(pad=0)\n",
    "# plt.savefig('part4_results/resized_thomas.jpg', bbox_inches='tight', pad_inches=0)\n",
    "\n",
    "import cv2 as cv\n",
    "h, w = cropped_thomas.shape[:2]\n",
    "resized_average = cv.resize(average_smiling_man, (w, h), interpolation = cv.INTER_AREA)\n",
    "# plt.imshow(resized_average)\n",
    "# plt.axis('off')\n",
    "# plt.tight_layout(pad=0)\n",
    "# plt.savefig('part4_results/resized_average.jpg', bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute triangulation for image via Delaunay function\n",
    "with open('points/resized_thomas_resized_average.json') as f:\n",
    "    correspondences = json.load(f)\n",
    "    points_thomas = np.array(correspondences[f'im1Points'])\n",
    "    points_avg = np.array(correspondences[f'im2Points'])\n",
    "    tri = Delaunay(points_thomas)\n",
    "\n",
    "warped_thomas = warp(cropped_thomas, points_thomas, points_avg, tri)\n",
    "warped_average = warp(resized_average, points_avg, points_thomas, tri)\n",
    "\n",
    "# plt.imshow(warped_thomas)\n",
    "# plt.axis('off')\n",
    "# plt.tight_layout(pad=0)\n",
    "# plt.savefig('part4_results/thomas_to_average.jpg', bbox_inches='tight', pad_inches=0)\n",
    "\n",
    "# plt.imshow(warped_average)\n",
    "# plt.axis('off')\n",
    "# plt.tight_layout(pad=0)\n",
    "# plt.savefig('part4_results/average_to_thomas.jpg', bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 5: Caricatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1.25\n",
    "caricature_points = alpha * (points_thomas - points_avg) + points_avg\n",
    "caricature_im = warp(cropped_thomas, points_thomas, caricature_points, tri)\n",
    "\n",
    "# plt.imshow(caricature_im)\n",
    "# plt.axis('off')\n",
    "# plt.tight_layout(pad=0)\n",
    "# plt.savefig('part5_results/caricature_1dot25.jpg', bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bells & Whistles: Music video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chopin, brahms, armstrong, sinatra, elvis, whitney, tupac, kanye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_directory = os.path.join(os.getcwd(), 'photos', 'bnw')\n",
    "# artists = os.listdir(video_directory)\n",
    "# filenames = [f for f in artists if os.path.isfile(os.path.join(video_directory, f))]\n",
    "# filenames_without_ext = [os.path.splitext(f)[0] for f in filenames] # Remove the extensions\n",
    "\n",
    "files = ['armstrong','sinatra','kanye','tupac','brahms','elvis','chopin','whitney']\n",
    "\n",
    "output_size = (481, 392)\n",
    "\n",
    "for filename in files:\n",
    "    # Load the image\n",
    "    img_path = os.path.join(video_directory, filename + '.jpg')\n",
    "    img = skio.imread(img_path)\n",
    "\n",
    "    # Resize the image\n",
    "    resized_img = sk.transform.resize(img, output_size, anti_aliasing=True)\n",
    "\n",
    "    # Save the resized image\n",
    "    output_path = os.path.join(os.path.join(os.getcwd(), 'photos', 'bnw_scaled'), filename + '.jpg')\n",
    "    skio.imsave(output_path, (resized_img * 255).astype('uint8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im1 = sk.img_as_float(plt.imread(f'photos/bnw_scaled/chopin.jpg')/255)\n",
    "im2 = sk.img_as_float(plt.imread(f'photos/bnw_scaled/brahms.jpg')/255)\n",
    "im1_points, tri = triangulate(1, 'na')\n",
    "im2_points, _ = triangulate(2, 'na')\n",
    "morphed_im = morph(im1, im2, im1_points, im2_points, tri, 0.5, 0.5)\n",
    "plt.imshow(morphed_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = []\n",
    "\n",
    "def morph_ims(im1_file, im2_file, points_file):\n",
    "    im1 = sk.img_as_float(plt.imread(f'photos/bnw_scaled/{im1_file}')/255)\n",
    "    im2 = sk.img_as_float(plt.imread(f'photos/bnw_scaled/{im2_file}')/255)\n",
    "    im1_points, tri = triangulate(1, 'na')\n",
    "    im2_points, _ = triangulate(2, 'na')\n",
    "    # morphed_im = morph(im1, im2, im1_points, im2_points, tri, 0.5, 0.5)\n",
    "\n",
    "    frames = []\n",
    "    num_frames = 45\n",
    "\n",
    "    for frame in range(num_frames):\n",
    "        threshold = frame / (num_frames - 1)\n",
    "        morphed_im = morph(im1, im2, im1_points, im2_points, tri, threshold, threshold)\n",
    "        frames.append(morphed_im)\n",
    "\n",
    "    # Convert each frame to uint8\n",
    "    frames = [np.clip(frame, 0, 1) * 255 for frame in frames]\n",
    "    frames = [frame.astype(np.uint8) for frame in frames]\n",
    "\n",
    "    return frames\n",
    "\n",
    "video.extend(morph_ims('brahms.jpg', 'chopin.jpg', 'points/chopin_brahms.json'))\n",
    "video.extend(morph_ims('armstrong.jpg', 'brahms.jpg', 'points/brahms_armstrong.json'))\n",
    "video.extend(morph_ims('sinatra.jpg', 'armstrong.jpg', 'points/armstrong_sinatra.json'))\n",
    "video.extend(morph_ims('elvis.jpg', 'sinatra.jpg', 'points/sinatra_elvis.json'))\n",
    "video.extend(morph_ims('whitney.jpg', 'elvis.jpg', 'points/elvis_whitney.json'))\n",
    "video.extend(morph_ims('tupac.jpg', 'whitney.jpg', 'points/whitney_tupac.json'))\n",
    "video.extend(morph_ims('kanye.jpg', 'tupac.jpg', 'points/tupac_kanye.json'))\n",
    "\n",
    "imageio.mimsave('bnw_results/morphed.gif', video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define video properties\n",
    "height, width, layers = video[0].shape\n",
    "fps = 30\n",
    "output_file = 'bnw_results/morphed.mp4'\n",
    "fourcc = cv.VideoWriter_fourcc(*'mp4v')\n",
    "\n",
    "# Create video writer\n",
    "out = cv.VideoWriter(output_file, fourcc, fps, (width, height))\n",
    "\n",
    "# Write frames to video\n",
    "for frame in video:\n",
    "    # Convert frame from RGB to BGR to fix color channel interpretation\n",
    "    if len(frame.shape) == 3:\n",
    "        frame = cv.cvtColor(frame, cv.COLOR_RGB2BGR)\n",
    "    elif len(frame.shape) == 2:\n",
    "        frame = cv.cvtColor(frame, cv.COLOR_GRAY2BGR)\n",
    "    out.write(frame)\n",
    "\n",
    "# Release the video writer\n",
    "out.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "180p3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
